# arguments for dataset
dataset: loveda
nclass: 8
crop_size: 513
data_root: /data/fyao309/AllSpark/loveda

# arguments for training
epochs: 240
batch_size: 4 # per GPU x 4 GPUs
lr: 0.005
lr_multi: 1.0

criterion:
  name: OHEM
  kwargs:
    ignore_index: 255
    thresh: 0.7
    min_kept: 200000


criterion_u:
  name: CELoss
  kwargs:
    ignore_index: 255

# arguments for model
model:
  backbone:
    type: model.backbone.mit.mit_b5
    kwargs:
      embed_dims: [64, 128, 320, 512]
      pretrained: True
      
  decoder:
    type: model.semseg.finegrained.SemiDecoder
    kwargs:
      num_heads: 2
      num_class: 8
      in_planes: [64, 128, 320, 512]
      image_size: 513
      warmup_epoch: 15
      embedding_dim: 768
      output_dim: 512
